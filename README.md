# Keypoint Regression

<Здесь описание проекта>

> Все команды запускаются из корня проекта

### Подготовка окружения

```bash
sudo apt install pipx
pipx install uv
uv sync
```

### Запуск обучения

ЧТобы запустить обучение в train нужн оподать одноканальные изображения и csv файл с разметкой на эти изображения

> В репозитории сохранены необходимые файлы разметки, ссылка на полный датасет: jsdlfkjsalkfj

С помощью `src/config.py` можно настраивать обучение: для начала обучения необходимо прописать соответствующие пути до датасетов

#### Обучение регрессора:

Датасет:
...

```bash
uv run scripts/train_reg.py
```

#### Обучение классификатора:

Датасет:
...

```bash
uv run scripts/train_cl.py
```

> По дефолту будет создаваться новая чекпоинт-директория для каждого запуска обучения. Однако для работы последующих этапов

На первом этапе валидации будет создана папка в `data/checkpoints`, где сохраняются лучшие веса (отбираются по метрике ...), примеры работы с картинками.

### Запуск конвертации весов .pth -> .tflite

```bash
uv run scripts/convert --checkpoint <путь до папки с чекпоинтом>
```

Веса в формате .tflite сохраняются в той же директории чекпоинта

### Бенчмарк

```bash
uv run scripts/evaluate --regressor <> --classifier <>
```

Вычисляются метрики Accuracy, Precision, Recall, F1 macro average

Результаты сохраняются в отдельной чекпоинт-директории
Результаты бенчмарка сохранятся в `data/checkpoints/metrics_<checkpoint time>`

### Инференс на [Coral](<ссылка на Coral>)

Подготовка

Установка docker

Подключение Coral по быстрому проводу

```bash
bash scripts/inference.bash
```

При запуске будет сразу запущен скрипт `scripts/speed_test.py`, который вычисляет среднее время работы регрессора, классификатора и общее время работы
